{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e073ce1f",
   "metadata": {},
   "source": [
    "# Imports & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e80f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, diags, identity\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds, spsolve_triangular, eigsh, splu\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "from dataprep import (\n",
    "    generate_interactions_matrix,\n",
    "    leave_last_out,\n",
    "    transform_indices,\n",
    "    verify_time_split,\n",
    "    reindex_data,\n",
    ")\n",
    "from evaluation import (\n",
    "    topn_recommendations,\n",
    "    model_evaluate,\n",
    "    downvote_seen_items,\n",
    "    calculate_rmse,\n",
    "    postprocess_scores,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76271ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "319326a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273329",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_time(data: pd.DataFrame, split_time, userid=\"userid\", timeid=\"timestamp\"):\n",
    "\n",
    "    test_users = data[data[timeid] > split_time][userid].unique()\n",
    "\n",
    "    return data[~data[userid].isin(test_users)], data[data[userid].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb086ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gower_sim(A, w=None):\n",
    "\n",
    "    mins = A.min(axis=0)\n",
    "    maxes = A.max(axis=0)\n",
    "    ranges = maxes - mins\n",
    "    ranges[ranges == 0] = 1.0\n",
    "\n",
    "    An = (A - mins) / ranges\n",
    "\n",
    "    _, d = An.shape\n",
    "    w = w if w is not None else np.ones(d)\n",
    "    assert w.size == d\n",
    "\n",
    "    diffs = An[:, None, :] - An[None, :, :]\n",
    "    diffs = np.abs(diffs)\n",
    "    diffs *= w\n",
    "\n",
    "    similarity = 1 - np.sum(diffs, axis=2) / np.sum(w)\n",
    "\n",
    "    similarity = csr_matrix(similarity)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4431963",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e6bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_zd(A):\n",
    "    \"\"\"Build cosine similarity matrix with zero diagonal.\"\"\"\n",
    "    A = csr_matrix(A)\n",
    "    similarity = cosine_similarity(A, dense_output=False)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def get_gower_sim(A, w=None):\n",
    "    mins = A.min(axis=0)\n",
    "    maxes = A.max(axis=0)\n",
    "    ranges = maxes - mins\n",
    "    ranges[ranges == 0] = 1.0\n",
    "\n",
    "    A = (A - mins) / ranges\n",
    "\n",
    "    n, d = A.shape\n",
    "    w = w if w is not None else np.ones(d)\n",
    "    assert w.size == d\n",
    "\n",
    "    Aw = A * w\n",
    "    D = cdist(Aw, Aw, metric=\"cityblock\") / np.sum(w)\n",
    "\n",
    "    similarity = 1 - D\n",
    "    similarity = csr_matrix(similarity)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def sparse_dropout(A, p=0.5):\n",
    "    # Randomly zero p of all elements\n",
    "    A_coo = A.tocoo()\n",
    "    nnz = A_coo.nnz\n",
    "    keep_indices = np.random.choice(nnz, size=int(nnz * (1 - p)), replace=False)\n",
    "    return csr_matrix(\n",
    "        (A_coo.data[keep_indices], (A_coo.row[keep_indices], A_coo.col[keep_indices])),\n",
    "        shape=A.shape,\n",
    "    )\n",
    "\n",
    "\n",
    "def topk(A, p=0.5):\n",
    "    # Leave only p of all elements per row\n",
    "    A = A.copy()\n",
    "    for i in range(A.shape[0]):\n",
    "        start, stop = A.indptr[i], A.indptr[i + 1]\n",
    "        row = A.data[start:stop]\n",
    "        k = int(len(row) * p)\n",
    "        keep_mask = np.zeros(len(row), dtype=bool)\n",
    "        keep_mask[np.argpartition(row, -k)[-k:]] = True\n",
    "        A.data[start:stop][~keep_mask] = 0\n",
    "    A.eliminate_zeros()\n",
    "    return A\n",
    "\n",
    "\n",
    "def build_iknn_model(config, data, data_description):\n",
    "    item_similarity = None\n",
    "    if config.get(\"gower\", False):\n",
    "        feats = data_description[\"item_features_mtx\"]\n",
    "        item_similarity = get_gower_sim(feats, config.get(\"gower_w\", None))\n",
    "    else:\n",
    "        item_similarity = cosine_similarity_zd(data_description[\"item_features_mtx\"])\n",
    "    if config.get(\"sampling\", True):\n",
    "        # we leave half of the samples and then only highest rated half\n",
    "        item_similarity = sparse_dropout(item_similarity, config.get(\"p_dropout\", 0.5))\n",
    "        item_similarity = topk(item_similarity, config.get(\"p_topk\", 0.5))\n",
    "    return item_similarity\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def iknn_model_scoring(params, testset, testset_description):\n",
    "    item_similarity = params\n",
    "    test_mtx = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "    scores = test_mtx @ item_similarity\n",
    "    return scores.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a04268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scoring(testset, testset_description):\n",
    "    test_mtx = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "    return np.random.rand(*test_mtx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacd6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easer_build(config, data, data_description):\n",
    "\n",
    "    gower = config[\"gower\"]\n",
    "    alpha = config[\"alpha\"]\n",
    "    l = config[\"l\"]\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description)\n",
    "    I = csr_matrix(np.eye(data_description[\"n_items\"]))\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "    if gower:\n",
    "        F = get_gower_sim(Y)\n",
    "    else:\n",
    "        F = cosine_similarity_zd(Y)\n",
    "        # F = csr_matrix(Y @ Y.T)\n",
    "        # F.setdiag(0)\n",
    "\n",
    "    G = A.T @ A + alpha * F + l * I\n",
    "\n",
    "    P = np.linalg.inv(G.toarray())\n",
    "    W = np.eye(A.shape[1]) - P / np.diag(P)\n",
    "    return W\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def easer_scoring(params, testset, testset_description):\n",
    "    W = params\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "\n",
    "    return A @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6ae0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(Y, mode, nnbrs=10):\n",
    "    if mode == \"gower\":\n",
    "        S = get_gower_sim(Y).toarray()\n",
    "    else:\n",
    "        S = cosine_similarity(Y, Y)\n",
    "\n",
    "    np.fill_diagonal(S, 0.0)\n",
    "\n",
    "    neighbors = np.argpartition(-S, nnbrs, axis=1)[:, :nnbrs]\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def fsSLIM_build(config, data, data_description):\n",
    "    nnbrs = config[\"nnbrs\"]\n",
    "    alpha_reg = config[\"alpha_reg\"]\n",
    "    beta_reg = config[\"beta_reg\"]\n",
    "    gower = config[\"gower\"]\n",
    "\n",
    "    assert alpha_reg + beta_reg > 0\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description)\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "\n",
    "    neighbours = knn(Y, \"gower\", nnbrs) if gower else knn(Y, \"cos_sim\", nnbrs)\n",
    "\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    W = np.zeros((n_items, n_items))\n",
    "\n",
    "    model = ElasticNet(\n",
    "        alpha=alpha_reg + beta_reg,\n",
    "        l1_ratio=alpha_reg / (alpha_reg + beta_reg),\n",
    "        fit_intercept=False,\n",
    "        positive=True,\n",
    "        max_iter=50,\n",
    "        tol=config.get(\"tol\", 1e-2),\n",
    "    )\n",
    "\n",
    "    for j in range(n_items):\n",
    "        idx = neighbours[j]\n",
    "\n",
    "        X = A[:, idx].toarray()\n",
    "        y = A[:, j].toarray().ravel()\n",
    "\n",
    "        model.fit(X, y)\n",
    "\n",
    "        W[idx, j] = model.coef_\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def fsSLIM_scoring(params, testset, testset_description):\n",
    "    W = params\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "    return A @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69eefd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spd_similarity(sim, gamma=0.9, eps=1e-6):\n",
    "    n = sim.shape[0]\n",
    "    I = sp.eye(n, format=\"csr\")\n",
    "\n",
    "    sim = 0.5 * (sim + sim.T)\n",
    "\n",
    "    sim = sim.copy()\n",
    "    sim.setdiag(1.0)\n",
    "\n",
    "    K = gamma * sim + (1 - gamma) * I\n",
    "\n",
    "    K = K + eps * I\n",
    "\n",
    "    return K\n",
    "\n",
    "\n",
    "def safe_dot_kernel(Y, eps=1e-6):\n",
    "    Y = Y.astype(np.float64)\n",
    "    norms = np.linalg.norm(Y, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    Y = Y / norms\n",
    "    K = csr_matrix(Y @ Y.T)\n",
    "    K.setdiag(1.0)\n",
    "    K = K + eps * sp.eye(K.shape[0], format=\"csr\")\n",
    "    return K\n",
    "\n",
    "\n",
    "def sparse_cholesky(A):\n",
    "    sparse_matrix = A.T @ A\n",
    "    sparse_matrix += 1e-6 * identity(sparse_matrix.shape[0])\n",
    "    n = sparse_matrix.shape[0]\n",
    "    LU = splu(sparse_matrix, diag_pivot_thresh=0.0, permc_spec=\"NATURAL\")\n",
    "\n",
    "    L = LU.L @ diags(LU.U.diagonal() ** 0.5)\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "def hysvd_build(config, data, data_description):\n",
    "    rank = config.get(\"rank\", 25)\n",
    "    gamma_s = config.get(\"gamma_s\", 1)\n",
    "    gamma_k = config.get(\"gamma_k\", 1)\n",
    "    gower = config.get(\"gower\", False)\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description).tocsr()\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "    X = data_description[\"user_features_mtx\"]\n",
    "    if gower:\n",
    "        S_sim = get_gower_sim(Y)\n",
    "        S = make_spd_similarity(S_sim, gamma=gamma_s)\n",
    "        K_sim = get_gower_sim(X)\n",
    "        K = make_spd_similarity(K_sim, gamma=gamma_k)\n",
    "    else:\n",
    "        S_sim = safe_dot_kernel(Y)\n",
    "        S = make_spd_similarity(S_sim, gamma=gamma_s)\n",
    "        K_sim = safe_dot_kernel(X)\n",
    "        K = make_spd_similarity(K_sim, gamma=gamma_k)\n",
    "\n",
    "    Ls = csr_matrix(np.linalg.cholesky(S.toarray()))\n",
    "    Lk = csr_matrix(np.linalg.cholesky(K.toarray()))\n",
    "\n",
    "    # Ls = sparse_cholesky(S)\n",
    "    # Lk = sparse_cholesky(K)\n",
    "\n",
    "    M = Lk.T @ A @ Ls\n",
    "\n",
    "    U_hat, s, VT_hat = svds(M, k=rank)\n",
    "    idx = np.argsort(-s)\n",
    "    s = s[idx]\n",
    "    U_hat = U_hat[:, idx]\n",
    "    V_hat = VT_hat[idx, :].T\n",
    "\n",
    "    V = spsolve_triangular(Ls.T.tocsr(), V_hat, lower=False)\n",
    "\n",
    "    LV = Ls @ V\n",
    "    RV = spsolve_triangular(Ls.T.tocsr(), V, lower=False)\n",
    "\n",
    "    return {\"LV\": LV, \"RV\": RV, \"singular_values\": s}\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def hysvd_scoring(params, testset, testset_description):\n",
    "    LV = params[\"LV\"]\n",
    "    RV = params[\"RV\"]\n",
    "\n",
    "    A_test = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "\n",
    "    return A_test @ LV @ RV.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_scaling(A, alpha):\n",
    "    item_pop = np.array(A.sum(axis=0)).ravel()\n",
    "    item_pop[item_pop == 0] = 1.0\n",
    "    D_alpha = sp.diags(item_pop ** (-alpha))\n",
    "    return D_alpha\n",
    "\n",
    "\n",
    "def eigenrec_build(config, data, data_description):\n",
    "    rank = config.get(\"rank\", 100)\n",
    "    alpha = config.get(\"alpha\", 0.5)\n",
    "    gamma = config.get(\"gamma\", 0.8)\n",
    "    gower = config.get(\"gower\", True)\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description).tocsr()\n",
    "\n",
    "    D_alpha = popularity_scaling(A, alpha)\n",
    "    A_scaled = A @ D_alpha\n",
    "\n",
    "    C = A_scaled.T @ A_scaled\n",
    "    C.setdiag(0)\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "\n",
    "    if gower:\n",
    "        S = get_gower_sim(Y)\n",
    "    else:\n",
    "        S = cosine_similarity_zd(Y)\n",
    "\n",
    "    W_sim = gamma * S + (1.0 - gamma) * C\n",
    "\n",
    "    W_sim = W_sim + 1e-6 * sp.eye(W_sim.shape[0], format=\"csr\")\n",
    "\n",
    "    vals, vecs = eigsh(W_sim, k=rank, which=\"LA\")\n",
    "\n",
    "    idx = np.argsort(-vals)\n",
    "    vals = vals[idx]\n",
    "    vecs = vecs[:, idx]\n",
    "\n",
    "    return {\"Q\": vecs, \"Lambda\": vals}\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def eigenrec_scoring(params, testset, testset_description):\n",
    "    Q = params[\"Q\"]\n",
    "    Lambda = params[\"Lambda\"]\n",
    "\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "\n",
    "    AQ = A @ Q\n",
    "    scores = (AQ * Lambda) @ Q.T\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c671290",
   "metadata": {},
   "source": [
    "# Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe08d3",
   "metadata": {},
   "source": [
    "## MovieLens1M & BX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def encode_features(\n",
    "    X: pd.DataFrame,\n",
    "    element_id: str,\n",
    "    movie_lens_flg: bool = False,\n",
    "    categorical: list[str] = None,\n",
    "    numerical: list[str] = None,\n",
    "    text: list[str] = None,\n",
    "    max_tfidf_features: int = 50,\n",
    "    scale_numeric: bool = True,\n",
    "    limit_categorical: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Encode heterogeneous features into a feature DataFrame.\n",
    "\n",
    "    limit_categorical:\n",
    "        dict like {\"Publisher\": 100, \"Book-Author\": 200}\n",
    "        keeps top-K categories, others -> 'OTHER'\n",
    "    \"\"\"\n",
    "\n",
    "    parts = []\n",
    "    if movie_lens_flg and \"genres\" in X.columns:\n",
    "        genre_ohe = X[\"genres\"].fillna(\"\").str.get_dummies(sep=\"|\").add_prefix(\"genre_\")\n",
    "        parts.append(genre_ohe)\n",
    "    if categorical:\n",
    "        X_cat_src = X[categorical].copy()\n",
    "\n",
    "        if limit_categorical:\n",
    "            for col, top_k in limit_categorical.items():\n",
    "                if col in X_cat_src.columns:\n",
    "                    top_values = X_cat_src[col].value_counts().head(top_k).index\n",
    "                    X_cat_src[col] = X_cat_src[col].where(\n",
    "                        X_cat_src[col].isin(top_values), \"OTHER\"\n",
    "                    )\n",
    "\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        X_cat = ohe.fit_transform(X_cat_src.fillna(\"NA\"))\n",
    "        cat_cols = ohe.get_feature_names_out(categorical)\n",
    "\n",
    "        X_cat_df = pd.DataFrame(X_cat, columns=cat_cols, index=X.index)\n",
    "        parts.append(X_cat_df)\n",
    "    if numerical:\n",
    "        X_num_df = X[numerical].copy()\n",
    "\n",
    "        for col in numerical:\n",
    "            X_num_df[col] = pd.to_numeric(X_num_df[col], errors=\"coerce\")\n",
    "            mean_val = X_num_df[col].mean()\n",
    "            X_num_df[col] = X_num_df[col].fillna(mean_val)\n",
    "\n",
    "        X_num = X_num_df.to_numpy(dtype=float)\n",
    "\n",
    "        if scale_numeric:\n",
    "            scaler = StandardScaler()\n",
    "            X_num = scaler.fit_transform(X_num)\n",
    "\n",
    "        X_num_df = pd.DataFrame(X_num, columns=numerical, index=X.index)\n",
    "        parts.append(X_num_df)\n",
    "    if text:\n",
    "        for col in text:\n",
    "            tfidf = TfidfVectorizer(\n",
    "                max_features=max_tfidf_features, stop_words=\"english\"\n",
    "            )\n",
    "            X_txt = tfidf.fit_transform(X[col].fillna(\"\").astype(str))\n",
    "            txt_cols = [f\"{col}_tfidf_{t}\" for t in tfidf.get_feature_names_out()]\n",
    "\n",
    "            X_txt_df = pd.DataFrame(X_txt.toarray(), columns=txt_cols, index=X.index)\n",
    "            parts.append(X_txt_df)\n",
    "    if not parts:\n",
    "        raise ValueError(\"No features were encoded\")\n",
    "    features_df = pd.concat(parts, axis=1)\n",
    "    result = pd.concat(\n",
    "        [X[[element_id]].reset_index(drop=True), features_df.reset_index(drop=True)],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49508895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_start_scenario(\n",
    "    feedback: pd.DataFrame,\n",
    "    time_quantile: float = 0.8,\n",
    "    user_col: str = \"userid\",\n",
    "    item_col: str = \"movieid\",\n",
    "    time_col=None,\n",
    "):\n",
    "    if time_col is None:\n",
    "        time_col = \"timestamp\"\n",
    "        feedback[time_col] = np.random.rand(len(feedback))\n",
    "\n",
    "    training_, testing_h_ = split_by_time(\n",
    "        feedback, feedback[time_col].quantile(time_quantile), userid=user_col\n",
    "    )\n",
    "\n",
    "    training, training_index = transform_indices(\n",
    "        training_, users=user_col, items=item_col\n",
    "    )\n",
    "\n",
    "    _, testset_h_index = transform_indices(testing_h_, users=user_col, items=item_col)\n",
    "\n",
    "    data_index = {}\n",
    "    data_index[\"users\"] = pd.Index(\n",
    "        list(training_index[\"users\"]) + list(testset_h_index[\"users\"]), name=user_col\n",
    "    )\n",
    "    data_index[\"items\"] = training_index[\"items\"]\n",
    "\n",
    "    testset_h = reindex_data(\n",
    "        data=testing_h_,\n",
    "        data_index=data_index,\n",
    "        entities=[\"items\", \"users\"],\n",
    "        filter_invalid=True,\n",
    "    )\n",
    "\n",
    "    testset, holdout_ = leave_last_out(testset_h, userid=user_col)\n",
    "    holdout_ = holdout_[holdout_[user_col].isin(testset[user_col])]\n",
    "    holdout = holdout_.sort_values(user_col)\n",
    "\n",
    "    return training, data_index, testset, holdout, training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd1117bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/nqqr1_9n4yggqqgcpdv46_q40000gn/T/ipykernel_28925/3064727987.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feedback[time_col] = np.random.rand(len(feedback))\n",
      "/var/folders/vm/nqqr1_9n4yggqqgcpdv46_q40000gn/T/ipykernel_28925/3064727987.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feedback[time_col] = np.random.rand(len(feedback))\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data/\")\n",
    "\n",
    "feedback_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"userid\", \"movieid\", \"rating\", \"timestamp\"],\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "items_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"movieid\", \"title\", \"genres\"],\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "users_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/users.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"userid\", \"sex\", \"age\", \"occupation\", \"zipcode\"],\n",
    "    encoding=\"latin-1\",\n",
    ").drop(columns=[\"zipcode\"])\n",
    "\n",
    "\n",
    "feedback_bx = pd.read_csv(\n",
    "    data_dir / \"bx/BX-Book-Ratings.csv\", delimiter=\";\", encoding=\"latin1\"\n",
    ")\n",
    "\n",
    "items_bx = pd.read_csv(\n",
    "    data_dir / \"bx/BX-Books.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"latin-1\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "users_bx = pd.read_csv(\n",
    "    data_dir / \"bx/BX-Users.csv\",\n",
    "    delimiter=\";\",\n",
    "    encoding=\"latin-1\",\n",
    "    on_bad_lines=\"skip\",\n",
    "    low_memory=False,\n",
    ")\n",
    "users_bx[[\"Location_1\", \"Location_2\", \"Location_3\"]] = (\n",
    "    users_bx[\"Location\"].str.split(r\"\\s*,\\s*\", expand=True).iloc[:, :3]\n",
    ")\n",
    "users_bx = users_bx.drop(columns=[\"Location\"])\n",
    "users_bx[\"Age\"] = users_bx[\"Age\"].fillna(users_bx[\"Age\"].median())\n",
    "\n",
    "isbn_index = pd.Index(items_bx[\"ISBN\"].unique(), name=\"ISBN\")\n",
    "isbn_to_id = {isbn: i for i, isbn in enumerate(isbn_index)}\n",
    "items_bx = items_bx.copy()\n",
    "items_bx[\"ISBN\"] = items_bx[\"ISBN\"].map(isbn_to_id)\n",
    "feedback_bx = feedback_bx.copy()\n",
    "feedback_bx[\"ISBN\"] = feedback_bx[\"ISBN\"].map(isbn_to_id)\n",
    "\n",
    "\n",
    "training, data_index, testset, holdout, feedback_val = cold_start_scenario(\n",
    "    feedback_ml, time_col=\"timestamp\"\n",
    ")\n",
    "item_features_ = encode_features(\n",
    "    items_ml, element_id=\"movieid\", categorical=[], text=[\"title\"], movie_lens_flg=True\n",
    ")\n",
    "user_features_ = encode_features(\n",
    "    users_ml,\n",
    "    element_id=\"userid\",\n",
    "    categorical=[\"sex\", \"occupation\"],\n",
    "    text=[],\n",
    "    numerical=[\"age\"],\n",
    ")\n",
    "\n",
    "item_features = reindex_data(\n",
    "    data=item_features_, data_index=data_index, entities=[\"items\"], filter_invalid=True\n",
    ")\n",
    "user_features = reindex_data(\n",
    "    data=user_features_,\n",
    "    data_index=data_index,\n",
    "    entities=[\"users\"],\n",
    "    filter_invalid=True,\n",
    ")\n",
    "\n",
    "training_val, data_index_val, testset_val, holdout_val, _ = cold_start_scenario(\n",
    "    feedback_val, time_quantile=0.5\n",
    ")\n",
    "item_features_val = reindex_data(\n",
    "    data=item_features_,\n",
    "    data_index=data_index_val,\n",
    "    entities=[\"items\"],\n",
    "    filter_invalid=True,\n",
    ")\n",
    "\n",
    "\n",
    "training_bx, data_index_bx, testset_bx, holdout_bx, feedback_bx_val = (\n",
    "    cold_start_scenario(\n",
    "        feedback_bx, user_col=\"UserID\", item_col=\"ISBN\", time_quantile=0.05\n",
    "    )\n",
    ")\n",
    "training_bx = training_bx[training_bx[\"ISBN\"] > 0]\n",
    "item_features_bx_ = encode_features(\n",
    "    items_bx,\n",
    "    element_id=\"ISBN\",\n",
    "    categorical=[\"Book-Author\", \"Publisher\"],\n",
    "    numerical=[\"Year-Of-Publication\"],\n",
    "    text=[\"Book-Title\"],\n",
    "    limit_categorical={\n",
    "        \"Publisher\": 10,\n",
    "        \"Book-Author\": 10,\n",
    "    },\n",
    ")\n",
    "user_features_bx_ = encode_features(\n",
    "    users_bx,\n",
    "    element_id=\"UserID\",\n",
    "    categorical=[\"Location_1\", \"Location_2\", \"Location_3\"],\n",
    "    text=[],\n",
    "    numerical=[\"Age\"],\n",
    "    limit_categorical={\n",
    "        \"Location_1\": 10,\n",
    "        \"Location_2\": 10,\n",
    "        \"Location_3\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "item_features_bx = reindex_data(\n",
    "    data=item_features_bx_,\n",
    "    data_index=data_index_bx,\n",
    "    entities=[\"items\"],\n",
    "    filter_invalid=True,\n",
    ")\n",
    "user_features_bx = reindex_data(\n",
    "    data=user_features_bx_,\n",
    "    data_index=data_index_bx,\n",
    "    entities=[\"users\"],\n",
    "    filter_invalid=True,\n",
    ")\n",
    "\n",
    "\n",
    "training_bx_val, data_index_bx_val, testset_bx_val, holdout_bx_val, _ = (\n",
    "    cold_start_scenario(\n",
    "        feedback_bx_val, item_col=\"ISBN\", user_col=\"UserID\", time_quantile=0.5\n",
    "    )\n",
    ")\n",
    "item_features_bx_val = reindex_data(\n",
    "    data=item_features_bx_,\n",
    "    data_index=data_index_bx_val,\n",
    "    entities=[\"items\"],\n",
    "    filter_invalid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a7c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users=data_index[\"users\"].name,\n",
    "    items=data_index[\"items\"].name,\n",
    "    feedback=\"rating\",\n",
    "    n_users=len(data_index[\"users\"]),\n",
    "    n_items=len(data_index[\"items\"]),\n",
    "    test_users=holdout[data_index[\"users\"].name].values,\n",
    "    item_features_mtx=item_features.to_numpy(dtype=float),\n",
    "    user_features_mtx=user_features.to_numpy(dtype=float),\n",
    ")\n",
    "\n",
    "data_description_val = dict(\n",
    "    users=data_index_val[\"users\"].name,\n",
    "    items=data_index_val[\"items\"].name,\n",
    "    feedback=\"rating\",\n",
    "    n_users=len(data_index_val[\"users\"]),\n",
    "    n_items=len(data_index_val[\"items\"]),\n",
    "    test_users=holdout_val[data_index_val[\"users\"].name].values,\n",
    "    item_features_mtx=item_features_val.to_numpy(dtype=float),\n",
    "    user_features_mtx=None,\n",
    ")\n",
    "\n",
    "data_description_bx = dict(\n",
    "    users=data_index_bx[\"users\"].name,\n",
    "    items=data_index_bx[\"items\"].name,\n",
    "    feedback=\"Book-Rating\",\n",
    "    n_users=len(data_index_bx[\"users\"]),\n",
    "    n_items=len(data_index_bx[\"items\"]),\n",
    "    test_users=holdout_bx[data_index_bx[\"users\"].name].values,\n",
    "    item_features_mtx=item_features_bx.to_numpy(dtype=float),\n",
    "    user_features_mtx=user_features_bx.to_numpy(dtype=float),\n",
    ")\n",
    "\n",
    "# data_description_val_bx = dict(\n",
    "#     users = data_index_val['users'].name,\n",
    "#     items = data_index_val['items'].name,\n",
    "#     feedback = 'rating',\n",
    "#     n_users = len(data_index_val['users']),\n",
    "#     n_items = len(data_index_val['items']),\n",
    "#     test_users = holdout_val[data_index_val['users'].name].values,\n",
    "#     item_features_mtx = item_features_val.to_numpy(dtype=float),\n",
    "#     user_features_mtx=None,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d29b41",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57c58bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(\n",
    "    configs,\n",
    "    build_fn,\n",
    "    scoring_fn,\n",
    "    training,\n",
    "    testset,\n",
    "    holdout,\n",
    "    data_description,\n",
    "    topn: int = 10,\n",
    "    model_name: str = None,\n",
    "):\n",
    "    res = []\n",
    "\n",
    "    for config in tqdm(\n",
    "        configs, desc=f\"Running {model_name}\" if model_name else \"Running ...\"\n",
    "    ):\n",
    "        params = build_fn(\n",
    "            config=config, data=training, data_description=data_description\n",
    "        )\n",
    "\n",
    "        scores = scoring_fn(params, testset, data_description)\n",
    "\n",
    "        recs = topn_recommendations(scores, topn=topn)\n",
    "\n",
    "        metrics = model_evaluate(recs, holdout, data_description, topn=topn)\n",
    "\n",
    "        row = {}\n",
    "        if model_name is not None:\n",
    "            row[\"model\"] = model_name\n",
    "        else:\n",
    "            row[\"model\"] = \"noname\"\n",
    "\n",
    "        row[\"is_gower\"] = config[\"gower\"]\n",
    "        row.update(metrics._asdict())\n",
    "\n",
    "        res.append(row)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a9596f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"knn\": (build_iknn_model, iknn_model_scoring),\n",
    "    \"EASER\": (easer_build, easer_scoring),\n",
    "    \"fsSLIM\": (fsSLIM_build, fsSLIM_scoring),\n",
    "    \"HySVD\": (hysvd_build, hysvd_scoring),\n",
    "    \"EigenRec\": (eigenrec_build, eigenrec_scoring),\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"knn\": [\n",
    "        {\"sampling\": False, \"gower\": True},\n",
    "        {\"sampling\": False, \"gower\": False},\n",
    "    ],\n",
    "    \"EASER\": [\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": True},\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": False},\n",
    "    ],\n",
    "    \"fsSLIM\": [\n",
    "        {\"nnbrs\": 50, \"alpha_reg\": 1e-3, \"beta_reg\": 1e-1, \"gower\": True},\n",
    "        {\"nnbrs\": 50, \"alpha_reg\": 1e-3, \"beta_reg\": 1e-1, \"gower\": False},\n",
    "    ],\n",
    "    \"HySVD\": [\n",
    "        {\"gower\": True, \"rank\": 35},\n",
    "        {\"gower\": False, \"rank\": 35},\n",
    "    ],\n",
    "    \"EigenRec\": [{\"gower\": True, \"rank\": 50}, {\"gower\": False, \"rank\": 50}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8263b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running knn: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]\n",
      "Running EASER: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]\n",
      "Running fsSLIM: 100%|██████████| 2/2 [00:18<00:00,  9.22s/it]\n",
      "Running HySVD: 100%|██████████| 2/2 [00:44<00:00, 22.32s/it]\n",
      "Running EigenRec: 100%|██████████| 2/2 [00:05<00:00,  2.80s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>is_gower</th>\n",
       "      <th>HR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.105968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.270496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASER</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.065059</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.258784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.257111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>True</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>False</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.012828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.098438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>False</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.085332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  is_gower        HR       MRR  Coverage\n",
       "0       knn      True  0.003926  0.001064  0.105968\n",
       "1       knn     False  0.006169  0.002085  0.270496\n",
       "2     EASER      True  0.064498  0.023526  0.288622\n",
       "3     EASER     False  0.064498  0.023526  0.288622\n",
       "4    fsSLIM      True  0.065059  0.021077  0.258784\n",
       "5    fsSLIM     False  0.060572  0.021082  0.257111\n",
       "6     HySVD      True  0.023556  0.009088  0.013385\n",
       "7     HySVD     False  0.008974  0.002344  0.012828\n",
       "8  EigenRec      True  0.047672  0.017062  0.098438\n",
       "9  EigenRec     False  0.045990  0.018376  0.085332"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for name, (build_fn, scoring_fn) in models.items():\n",
    "    result += compare_models(\n",
    "        configs=model_configs[name],\n",
    "        build_fn=build_fn,\n",
    "        scoring_fn=scoring_fn,\n",
    "        training=training,\n",
    "        testset=testset,\n",
    "        holdout=holdout,\n",
    "        data_description=data_description,\n",
    "        model_name=name,\n",
    "    )\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0bbcf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationMetrics(HR=0.002243409983174425, MRR=0.0011217049915872126, Coverage=0.9947016174010039)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluate(\n",
    "    topn_recommendations(random_scoring(testset, data_description), 10),\n",
    "    holdout,\n",
    "    data_description,\n",
    "    10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82ac61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we omit HybridSVD on Book Crossing due to technical constraints\n",
    "\n",
    "models = {\n",
    "    \"knn\": (build_iknn_model, iknn_model_scoring),\n",
    "    \"EASER\": (easer_build, easer_scoring),\n",
    "    \"fsSLIM\": (fsSLIM_build, fsSLIM_scoring),\n",
    "    \"EigenRec\": (eigenrec_build, eigenrec_scoring),\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"knn\": [\n",
    "        {\"sampling\": False, \"gower\": True},\n",
    "        {\"sampling\": False, \"gower\": False},\n",
    "    ],\n",
    "    \"EASER\": [\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": True},\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": False},\n",
    "    ],\n",
    "    \"fsSLIM\": [\n",
    "        {\n",
    "            \"nnbrs\": 50,\n",
    "            \"alpha_reg\": 0,\n",
    "            \"beta_reg\": 1e-3,\n",
    "            \"gower\": True,\n",
    "        },\n",
    "        {\"nnbrs\": 50, \"alpha_reg\": 0, \"beta_reg\": 1e-3, \"gower\": False},\n",
    "    ],\n",
    "    \"EigenRec\": [{\"gower\": True, \"rank\": 50}, {\"gower\": False, \"rank\": 50}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a66d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running knn: 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]\n",
      "Running EASER: 100%|██████████| 2/2 [00:01<00:00,  1.92it/s]\n",
      "Running fsSLIM: 100%|██████████| 2/2 [03:41<00:00, 110.98s/it]\n",
      "Running EigenRec: 100%|██████████| 2/2 [00:01<00:00,  1.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>is_gower</th>\n",
       "      <th>HR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>0.017882</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.823908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>False</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.848276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>0.022486</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EASER</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.007361</td>\n",
       "      <td>0.259770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.068046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.068046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.435862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>False</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.002605</td>\n",
       "      <td>0.191264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  is_gower        HR       MRR  Coverage\n",
       "0       knn      True  0.017882  0.006551  0.823908\n",
       "1       knn     False  0.017351  0.006230  0.848276\n",
       "2     EASER      True  0.022486  0.008475  0.896552\n",
       "3     EASER     False  0.021335  0.007361  0.259770\n",
       "4    fsSLIM      True  0.004338  0.001312  0.068046\n",
       "5    fsSLIM     False  0.004338  0.001312  0.068046\n",
       "6  EigenRec      True  0.007436  0.002100  0.435862\n",
       "7  EigenRec     False  0.009738  0.002605  0.191264"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for name, (build_fn, scoring_fn) in models.items():\n",
    "    result += compare_models(\n",
    "        configs=model_configs[name],\n",
    "        build_fn=build_fn,\n",
    "        scoring_fn=scoring_fn,\n",
    "        training=training_bx,\n",
    "        testset=testset_bx,\n",
    "        holdout=holdout_bx,\n",
    "        data_description=data_description_bx,\n",
    "        model_name=name,\n",
    "    )\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4463688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationMetrics(HR=0.0048689801699716715, MRR=0.0011833799856108636, Coverage=1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluate(\n",
    "    topn_recommendations(random_scoring(testset_bx, data_description_bx), 10),\n",
    "    holdout_bx,\n",
    "    data_description_bx,\n",
    "    10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
