{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e073ce1f",
   "metadata": {},
   "source": [
    "# Imports & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e80f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse import csr_matrix, diags, identity\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds, spsolve_triangular, eigsh, splu\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "from dataprep import (\n",
    "    generate_interactions_matrix,\n",
    "    leave_last_out,\n",
    "    transform_indices,\n",
    "    verify_time_split,\n",
    "    reindex_data,\n",
    ")\n",
    "from evaluation import (\n",
    "    topn_recommendations,\n",
    "    model_evaluate,\n",
    "    downvote_seen_items,\n",
    "    calculate_rmse,\n",
    "    postprocess_scores,\n",
    ")\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool, EFstrType\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319326a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee273329",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d168639",
   "metadata": {},
   "outputs": [],
   "source": [
    "gower_w_pass = {\"item_feats\": None, \"user_feats\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981e5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_time(data: pd.DataFrame, split_time, userid=\"userid\", timeid=\"timestamp\"):\n",
    "\n",
    "    test_users = data[data[timeid] > split_time][userid].unique()\n",
    "\n",
    "    return data[~data[userid].isin(test_users)], data[data[userid].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb086ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gower_sim(A, w=None):\n",
    "\n",
    "    mins = A.min(axis=0)\n",
    "    maxes = A.max(axis=0)\n",
    "    ranges = maxes - mins\n",
    "    ranges[ranges == 0] = 1.0\n",
    "\n",
    "    An = (A - mins) / ranges\n",
    "\n",
    "    _, d = An.shape\n",
    "    w = w if w is not None else np.ones(d)\n",
    "    assert w.size == d\n",
    "\n",
    "    diffs = An[:, None, :] - An[None, :, :]\n",
    "    diffs = np.abs(diffs)\n",
    "    diffs *= w\n",
    "\n",
    "    similarity = 1 - np.sum(diffs, axis=2) / np.sum(w)\n",
    "\n",
    "    similarity = csr_matrix(similarity)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4431963",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e6bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_zd(A):\n",
    "    \"\"\"Build cosine similarity matrix with zero diagonal.\"\"\"\n",
    "    A = csr_matrix(A)\n",
    "    similarity = cosine_similarity(A, dense_output=False)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def get_gower_sim(A, w=None):\n",
    "    mins = A.min(axis=0)\n",
    "    maxes = A.max(axis=0)\n",
    "    ranges = maxes - mins\n",
    "    ranges[ranges == 0] = 1.0\n",
    "\n",
    "    A = (A - mins) / ranges\n",
    "\n",
    "    n, d = A.shape\n",
    "    w = w if w is not None else np.ones(d)\n",
    "    assert w.size == d\n",
    "\n",
    "    Aw = A * w\n",
    "    D = cdist(Aw, Aw, metric=\"cityblock\") / np.sum(w)\n",
    "\n",
    "    similarity = 1 - D\n",
    "    similarity = csr_matrix(similarity)\n",
    "    similarity.setdiag(0)\n",
    "    similarity.eliminate_zeros()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def sparse_dropout(A, p=0.5):\n",
    "    # Randomly zero p of all elements\n",
    "    A_coo = A.tocoo()\n",
    "    nnz = A_coo.nnz\n",
    "    keep_indices = np.random.choice(nnz, size=int(nnz * (1 - p)), replace=False)\n",
    "    return csr_matrix(\n",
    "        (A_coo.data[keep_indices], (A_coo.row[keep_indices], A_coo.col[keep_indices])),\n",
    "        shape=A.shape,\n",
    "    )\n",
    "\n",
    "\n",
    "def topk(A, p=0.5):\n",
    "    # Leave only p of all elements per row\n",
    "    A = A.copy()\n",
    "    for i in range(A.shape[0]):\n",
    "        start, stop = A.indptr[i], A.indptr[i + 1]\n",
    "        row = A.data[start:stop]\n",
    "        k = int(len(row) * p)\n",
    "        keep_mask = np.zeros(len(row), dtype=bool)\n",
    "        keep_mask[np.argpartition(row, -k)[-k:]] = True\n",
    "        A.data[start:stop][~keep_mask] = 0\n",
    "    A.eliminate_zeros()\n",
    "    return A\n",
    "\n",
    "\n",
    "def build_iknn_model(config, data, data_description):\n",
    "    item_similarity = None\n",
    "    if config.get(\"gower\", False):\n",
    "        feats = data_description[\"item_features_mtx\"]\n",
    "        item_similarity = get_gower_sim(\n",
    "            feats, w=config.get(\"gower_w\", gower_w_pass)[\"item_feats\"]\n",
    "        )\n",
    "    else:\n",
    "        item_similarity = cosine_similarity_zd(data_description[\"item_features_mtx\"])\n",
    "    if config.get(\"sampling\", True):\n",
    "        # we leave half of the samples and then only highest rated half\n",
    "        item_similarity = sparse_dropout(item_similarity, config.get(\"p_dropout\", 0.5))\n",
    "        item_similarity = topk(item_similarity, config.get(\"p_topk\", 0.5))\n",
    "    return item_similarity\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def iknn_model_scoring(params, testset, testset_description):\n",
    "    item_similarity = params\n",
    "    test_mtx = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "    scores = test_mtx @ item_similarity\n",
    "    return scores.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a04268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scoring(testset, testset_description):\n",
    "    test_mtx = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "    return np.random.rand(*test_mtx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacd6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def easer_build(config, data, data_description):\n",
    "\n",
    "    gower = config[\"gower\"]\n",
    "    alpha = config[\"alpha\"]\n",
    "    l = config[\"l\"]\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description)\n",
    "    I = csr_matrix(np.eye(data_description[\"n_items\"]))\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "    if gower:\n",
    "        F = get_gower_sim(Y, w=config.get(\"gower_w\", gower_w_pass)[\"item_feats\"])\n",
    "    else:\n",
    "        F = cosine_similarity_zd(Y)\n",
    "        # F = csr_matrix(Y @ Y.T)\n",
    "        # F.setdiag(0)\n",
    "\n",
    "    G = A.T @ A + alpha * F + l * I\n",
    "\n",
    "    P = np.linalg.inv(G.toarray())\n",
    "    W = np.eye(A.shape[1]) - P / np.diag(P)\n",
    "    return W\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def easer_scoring(params, testset, testset_description):\n",
    "    W = params\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "\n",
    "    return A @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6ae0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(Y, mode, config, nnbrs=10):\n",
    "    if mode == \"gower\":\n",
    "        S = get_gower_sim(\n",
    "            Y, w=config.get(\"gower_w\", gower_w_pass)[\"item_feats\"]\n",
    "        ).toarray()\n",
    "    else:\n",
    "        S = cosine_similarity(Y, Y)\n",
    "\n",
    "    np.fill_diagonal(S, 0.0)\n",
    "\n",
    "    neighbors = np.argpartition(-S, nnbrs, axis=1)[:, :nnbrs]\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def fsSLIM_build(config, data, data_description):\n",
    "    nnbrs = config[\"nnbrs\"]\n",
    "    alpha_reg = config[\"alpha_reg\"]\n",
    "    beta_reg = config[\"beta_reg\"]\n",
    "    gower = config[\"gower\"]\n",
    "\n",
    "    assert alpha_reg + beta_reg > 0\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description)\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "\n",
    "    neighbours = (\n",
    "        knn(Y, \"gower\", config, nnbrs) if gower else knn(Y, \"cos_sim\", config, nnbrs)\n",
    "    )\n",
    "\n",
    "    n_items = data_description[\"n_items\"]\n",
    "    W = np.zeros((n_items, n_items))\n",
    "\n",
    "    model = ElasticNet(\n",
    "        alpha=alpha_reg + beta_reg,\n",
    "        l1_ratio=alpha_reg / (alpha_reg + beta_reg),\n",
    "        fit_intercept=False,\n",
    "        positive=True,\n",
    "        max_iter=50,\n",
    "        tol=config.get(\"tol\", 1e-2),\n",
    "    )\n",
    "\n",
    "    for j in range(n_items):\n",
    "        idx = neighbours[j]\n",
    "\n",
    "        X = A[:, idx].toarray()\n",
    "        y = A[:, j].toarray().ravel()\n",
    "\n",
    "        model.fit(X, y)\n",
    "\n",
    "        W[idx, j] = model.coef_\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def fsSLIM_scoring(params, testset, testset_description):\n",
    "    W = params\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "    return A @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69eefd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_spd_similarity(sim, gamma=0.9, eps=1e-6):\n",
    "    n = sim.shape[0]\n",
    "    I = sp.eye(n, format=\"csr\")\n",
    "\n",
    "    sim = 0.5 * (sim + sim.T)\n",
    "\n",
    "    sim = sim.copy()\n",
    "    sim.setdiag(1.0)\n",
    "\n",
    "    K = gamma * sim + (1 - gamma) * I\n",
    "\n",
    "    K = K + eps * I\n",
    "\n",
    "    return K\n",
    "\n",
    "\n",
    "def safe_dot_kernel(Y, eps=1e-6):\n",
    "    Y = Y.astype(np.float64)\n",
    "    norms = np.linalg.norm(Y, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1.0\n",
    "    Y = Y / norms\n",
    "    K = csr_matrix(Y @ Y.T)\n",
    "    K.setdiag(1.0)\n",
    "    K = K + eps * sp.eye(K.shape[0], format=\"csr\")\n",
    "    return K\n",
    "\n",
    "\n",
    "def sparse_cholesky(A):\n",
    "    sparse_matrix = A.T @ A\n",
    "    sparse_matrix += 1e-6 * identity(sparse_matrix.shape[0])\n",
    "    n = sparse_matrix.shape[0]\n",
    "    LU = splu(sparse_matrix, diag_pivot_thresh=0.0, permc_spec=\"NATURAL\")\n",
    "\n",
    "    L = LU.L @ diags(LU.U.diagonal() ** 0.5)\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "def hysvd_build(config, data, data_description):\n",
    "    rank = config.get(\"rank\", 25)\n",
    "    gamma_s = config.get(\"gamma_s\", 1)\n",
    "    gamma_k = config.get(\"gamma_k\", 1)\n",
    "    gower = config.get(\"gower\", False)\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description).tocsr()\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "    X = data_description[\"user_features_mtx\"]\n",
    "    if gower:\n",
    "        S_sim = get_gower_sim(Y, w=config.get(\"gower_w\", gower_w_pass)[\"item_feats\"])\n",
    "        S = make_spd_similarity(S_sim, gamma=gamma_s)\n",
    "        K_sim = get_gower_sim(X, w=config.get(\"gower_w\", gower_w_pass)[\"user_feats\"])\n",
    "        K = make_spd_similarity(K_sim, gamma=gamma_k)\n",
    "    else:\n",
    "        S_sim = safe_dot_kernel(Y)\n",
    "        S = make_spd_similarity(S_sim, gamma=gamma_s)\n",
    "        K_sim = safe_dot_kernel(X)\n",
    "        K = make_spd_similarity(K_sim, gamma=gamma_k)\n",
    "\n",
    "    Ls = csr_matrix(np.linalg.cholesky(S.toarray()))\n",
    "    Lk = csr_matrix(np.linalg.cholesky(K.toarray()))\n",
    "\n",
    "    # Ls = sparse_cholesky(S)\n",
    "    # Lk = sparse_cholesky(K)\n",
    "\n",
    "    M = Lk.T @ A @ Ls\n",
    "\n",
    "    U_hat, s, VT_hat = svds(M, k=rank)\n",
    "    idx = np.argsort(-s)\n",
    "    s = s[idx]\n",
    "    U_hat = U_hat[:, idx]\n",
    "    V_hat = VT_hat[idx, :].T\n",
    "\n",
    "    V = spsolve_triangular(Ls.T.tocsr(), V_hat, lower=False)\n",
    "\n",
    "    LV = Ls @ V\n",
    "    RV = spsolve_triangular(Ls.T.tocsr(), V, lower=False)\n",
    "\n",
    "    return {\"LV\": LV, \"RV\": RV, \"singular_values\": s}\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def hysvd_scoring(params, testset, testset_description):\n",
    "    LV = params[\"LV\"]\n",
    "    RV = params[\"RV\"]\n",
    "\n",
    "    A_test = generate_interactions_matrix(\n",
    "        testset, testset_description, rebase_users=True\n",
    "    )\n",
    "\n",
    "    return A_test @ LV @ RV.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e1a1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_scaling(A, alpha):\n",
    "    item_pop = np.array(A.sum(axis=0)).ravel()\n",
    "    item_pop[item_pop == 0] = 1.0\n",
    "    D_alpha = sp.diags(item_pop ** (-alpha))\n",
    "    return D_alpha\n",
    "\n",
    "\n",
    "def eigenrec_build(config, data, data_description):\n",
    "    rank = config.get(\"rank\", 100)\n",
    "    alpha = config.get(\"alpha\", 0.5)\n",
    "    gamma = config.get(\"gamma\", 0.8)\n",
    "    gower = config.get(\"gower\", True)\n",
    "\n",
    "    A = generate_interactions_matrix(data, data_description).tocsr()\n",
    "\n",
    "    D_alpha = popularity_scaling(A, alpha)\n",
    "    A_scaled = A @ D_alpha\n",
    "\n",
    "    C = A_scaled.T @ A_scaled\n",
    "    C.setdiag(0)\n",
    "\n",
    "    Y = data_description[\"item_features_mtx\"]\n",
    "\n",
    "    if gower:\n",
    "        S = get_gower_sim(Y, w=config.get(\"gower_w\", gower_w_pass)[\"item_feats\"])\n",
    "    else:\n",
    "        S = cosine_similarity_zd(Y)\n",
    "\n",
    "    W_sim = gamma * S + (1.0 - gamma) * C\n",
    "\n",
    "    W_sim = W_sim + 1e-6 * sp.eye(W_sim.shape[0], format=\"csr\")\n",
    "\n",
    "    vals, vecs = eigsh(W_sim, k=rank, which=\"LA\")\n",
    "\n",
    "    idx = np.argsort(-vals)\n",
    "    vals = vals[idx]\n",
    "    vecs = vecs[:, idx]\n",
    "\n",
    "    return {\"Q\": vecs, \"Lambda\": vals}\n",
    "\n",
    "\n",
    "@postprocess_scores\n",
    "def eigenrec_scoring(params, testset, testset_description):\n",
    "    Q = params[\"Q\"]\n",
    "    Lambda = params[\"Lambda\"]\n",
    "\n",
    "    A = generate_interactions_matrix(testset, testset_description, rebase_users=True)\n",
    "\n",
    "    AQ = A @ Q\n",
    "    scores = (AQ * Lambda) @ Q.T\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c671290",
   "metadata": {},
   "source": [
    "# Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfe08d3",
   "metadata": {},
   "source": [
    "## MovieLens1M & BX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "530fc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def encode_features(\n",
    "    X: pd.DataFrame,\n",
    "    element_id: str,\n",
    "    movie_lens_flg: bool = False,\n",
    "    categorical: list[str] = None,\n",
    "    numerical: list[str] = None,\n",
    "    text: list[str] = None,\n",
    "    max_tfidf_features: int = 50,\n",
    "    scale_numeric: bool = True,\n",
    "    limit_categorical: dict = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Encode heterogeneous features into a feature DataFrame.\n",
    "\n",
    "    limit_categorical:\n",
    "        dict like {\"Publisher\": 100, \"Book-Author\": 200}\n",
    "        keeps top-K categories, others -> 'OTHER'\n",
    "    \"\"\"\n",
    "\n",
    "    parts = []\n",
    "    if movie_lens_flg and \"genres\" in X.columns:\n",
    "        genre_ohe = X[\"genres\"].fillna(\"\").str.get_dummies(sep=\"|\").add_prefix(\"genre_\")\n",
    "        parts.append(genre_ohe)\n",
    "    if categorical:\n",
    "        X_cat_src = X[categorical].copy()\n",
    "\n",
    "        if limit_categorical:\n",
    "            for col, top_k in limit_categorical.items():\n",
    "                if col in X_cat_src.columns:\n",
    "                    top_values = X_cat_src[col].value_counts().head(top_k).index\n",
    "                    X_cat_src[col] = X_cat_src[col].where(\n",
    "                        X_cat_src[col].isin(top_values), \"OTHER\"\n",
    "                    )\n",
    "\n",
    "        ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "        X_cat = ohe.fit_transform(X_cat_src.fillna(\"NA\"))\n",
    "        cat_cols = ohe.get_feature_names_out(categorical)\n",
    "\n",
    "        X_cat_df = pd.DataFrame(X_cat, columns=cat_cols, index=X.index)\n",
    "        parts.append(X_cat_df)\n",
    "    if numerical:\n",
    "        X_num_df = X[numerical].copy()\n",
    "\n",
    "        for col in numerical:\n",
    "            X_num_df[col] = pd.to_numeric(X_num_df[col], errors=\"coerce\")\n",
    "            mean_val = X_num_df[col].mean()\n",
    "            X_num_df[col] = X_num_df[col].fillna(mean_val)\n",
    "\n",
    "        X_num = X_num_df.to_numpy(dtype=float)\n",
    "\n",
    "        if scale_numeric:\n",
    "            scaler = StandardScaler()\n",
    "            X_num = scaler.fit_transform(X_num)\n",
    "\n",
    "        X_num_df = pd.DataFrame(X_num, columns=numerical, index=X.index)\n",
    "        parts.append(X_num_df)\n",
    "    if text:\n",
    "        for col in text:\n",
    "            tfidf = TfidfVectorizer(\n",
    "                max_features=max_tfidf_features, stop_words=\"english\"\n",
    "            )\n",
    "            X_txt = tfidf.fit_transform(X[col].fillna(\"\").astype(str))\n",
    "            txt_cols = [f\"{col}_tfidf_{t}\" for t in tfidf.get_feature_names_out()]\n",
    "\n",
    "            X_txt_df = pd.DataFrame(X_txt.toarray(), columns=txt_cols, index=X.index)\n",
    "            parts.append(X_txt_df)\n",
    "    if not parts:\n",
    "        raise ValueError(\"No features were encoded\")\n",
    "    features_df = pd.concat(parts, axis=1)\n",
    "    result = pd.concat(\n",
    "        [X[[element_id]].reset_index(drop=True), features_df.reset_index(drop=True)],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49508895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cold_start_scenario(\n",
    "    feedback: pd.DataFrame,\n",
    "    time_quantile: float = 0.8,\n",
    "    user_col: str = \"userid\",\n",
    "    item_col: str = \"movieid\",\n",
    "    time_col=None,\n",
    "):\n",
    "    if time_col is None:\n",
    "        time_col = \"timestamp\"\n",
    "        feedback[time_col] = np.random.rand(len(feedback))\n",
    "\n",
    "    training_, testing_h_ = split_by_time(\n",
    "        feedback, feedback[time_col].quantile(time_quantile), userid=user_col\n",
    "    )\n",
    "\n",
    "    training, training_index = transform_indices(\n",
    "        training_, users=user_col, items=item_col\n",
    "    )\n",
    "\n",
    "    _, testset_h_index = transform_indices(testing_h_, users=user_col, items=item_col)\n",
    "\n",
    "    data_index = {}\n",
    "    data_index[\"users\"] = pd.Index(\n",
    "        list(training_index[\"users\"]) + list(testset_h_index[\"users\"]), name=user_col\n",
    "    )\n",
    "    data_index[\"items\"] = training_index[\"items\"]\n",
    "\n",
    "    testset_h = reindex_data(\n",
    "        data=testing_h_,\n",
    "        data_index=data_index,\n",
    "        entities=[\"items\", \"users\"],\n",
    "        filter_invalid=True,\n",
    "    )\n",
    "\n",
    "    testset, holdout_ = leave_last_out(testset_h, userid=user_col)\n",
    "    holdout_ = holdout_[holdout_[user_col].isin(testset[user_col])]\n",
    "    holdout = holdout_.sort_values(user_col)\n",
    "\n",
    "    return training, data_index, testset, holdout, training_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd1117bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/nqqr1_9n4yggqqgcpdv46_q40000gn/T/ipykernel_29543/3064727987.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feedback[time_col] = np.random.rand(len(feedback))\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data/\")\n",
    "\n",
    "feedback_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/ratings.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"userid\", \"movieid\", \"rating\", \"timestamp\"],\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "items_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/movies.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"movieid\", \"title\", \"genres\"],\n",
    "    encoding=\"latin-1\",\n",
    ")\n",
    "\n",
    "users_ml = pd.read_csv(\n",
    "    data_dir / \"ml-1m/users.dat\",\n",
    "    sep=\"::\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=[\"userid\", \"sex\", \"age\", \"occupation\", \"zipcode\"],\n",
    "    encoding=\"latin-1\",\n",
    ").drop(columns=[\"zipcode\"])\n",
    "\n",
    "training, data_index, testset, holdout, feedback_val = cold_start_scenario(\n",
    "    feedback_ml, time_col=\"timestamp\"\n",
    ")\n",
    "item_features_ = encode_features(\n",
    "    items_ml, element_id=\"movieid\", categorical=[], text=[\"title\"], movie_lens_flg=True\n",
    ")\n",
    "user_features_ = encode_features(\n",
    "    users_ml,\n",
    "    element_id=\"userid\",\n",
    "    categorical=[\"sex\", \"occupation\"],\n",
    "    text=[],\n",
    "    numerical=[\"age\"],\n",
    ")\n",
    "\n",
    "item_features = reindex_data(\n",
    "    data=item_features_, data_index=data_index, entities=[\"items\"], filter_invalid=True\n",
    ")\n",
    "user_features = reindex_data(\n",
    "    data=user_features_,\n",
    "    data_index=data_index,\n",
    "    entities=[\"users\"],\n",
    "    filter_invalid=True,\n",
    ")\n",
    "\n",
    "training_val, data_index_val, testset_val, holdout_val, _ = cold_start_scenario(\n",
    "    feedback_val, time_quantile=0.5\n",
    ")\n",
    "item_features_val = reindex_data(\n",
    "    data=item_features_,\n",
    "    data_index=data_index_val,\n",
    "    entities=[\"items\"],\n",
    "    filter_invalid=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09a7c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users=data_index[\"users\"].name,\n",
    "    items=data_index[\"items\"].name,\n",
    "    feedback=\"rating\",\n",
    "    n_users=len(data_index[\"users\"]),\n",
    "    n_items=len(data_index[\"items\"]),\n",
    "    test_users=holdout[data_index[\"users\"].name].values,\n",
    "    item_features_mtx=item_features.to_numpy(dtype=float),\n",
    "    user_features_mtx=user_features.to_numpy(dtype=float),\n",
    ")\n",
    "\n",
    "data_description_val = dict(\n",
    "    users=data_index_val[\"users\"].name,\n",
    "    items=data_index_val[\"items\"].name,\n",
    "    feedback=\"rating\",\n",
    "    n_users=len(data_index_val[\"users\"]),\n",
    "    n_items=len(data_index_val[\"items\"]),\n",
    "    test_users=holdout_val[data_index_val[\"users\"].name].values,\n",
    "    item_features_mtx=item_features_val.to_numpy(dtype=float),\n",
    "    user_features_mtx=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63109ca4",
   "metadata": {},
   "source": [
    "# Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc4a1352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9455215366549271\n"
     ]
    }
   ],
   "source": [
    "def get_importances(df, user_features, item_features, data_description):\n",
    "    df = df.copy()\n",
    "    df = df.merge(item_features, on=data_description[\"items\"], how=\"left\")\n",
    "    df = df.merge(user_features, on=data_description[\"users\"], how=\"left\")\n",
    "    cols = list(item_features.columns) + list(user_features.columns)\n",
    "    feedback_col = data_description[\"feedback\"]\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, random_state=42, test_size=0.2, shuffle=True\n",
    "    )\n",
    "    train_pool = Pool(train_df[cols], train_df[feedback_col])\n",
    "    test_pool = Pool(test_df[cols], test_df[feedback_col])\n",
    "    model = CatBoostRegressor(random_state=42, iterations=1000, verbose=False)\n",
    "    model.fit(train_pool)\n",
    "    print(f\"MSE: {mean_squared_error(test_pool.get_label(), model.predict(test_pool))}\")\n",
    "    perm = permutation_importance(\n",
    "        model,\n",
    "        test_df[cols],\n",
    "        test_pool.get_label(),\n",
    "        n_repeats=10,\n",
    "        random_state=42,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "    )[\"importances_mean\"]\n",
    "    perm -= max(0, perm.min())\n",
    "    shap_vals = model.get_feature_importance(test_pool, type=EFstrType.ShapValues)\n",
    "    shap = np.abs(shap_vals[:, :-1]).mean(axis=0)\n",
    "    norm = lambda x: x / sum(x)\n",
    "    split = lambda x: {\n",
    "        \"item_feats\": x[: len(item_features.columns)],\n",
    "        \"user_feats\": x[-len(user_features.columns) :],\n",
    "    }\n",
    "    return {\n",
    "        \"builtin\": split(norm(model.get_feature_importance())),\n",
    "        \"shap\": split(norm(shap)),\n",
    "        \"permutation\": split(norm(perm)),\n",
    "    }\n",
    "\n",
    "\n",
    "importances = get_importances(\n",
    "    training,\n",
    "    item_features=item_features,\n",
    "    user_features=user_features,\n",
    "    data_description=data_description,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d29b41",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57c58bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(\n",
    "    configs,\n",
    "    build_fn,\n",
    "    scoring_fn,\n",
    "    training,\n",
    "    testset,\n",
    "    holdout,\n",
    "    data_description,\n",
    "    topn: int = 10,\n",
    "    model_name: str = None,\n",
    "):\n",
    "    res = []\n",
    "\n",
    "    for config in tqdm(\n",
    "        configs, desc=f\"Running {model_name}\" if model_name else \"Running ...\"\n",
    "    ):\n",
    "        params = build_fn(\n",
    "            config=config, data=training, data_description=data_description\n",
    "        )\n",
    "\n",
    "        scores = scoring_fn(params, testset, data_description)\n",
    "\n",
    "        recs = topn_recommendations(scores, topn=topn)\n",
    "\n",
    "        metrics = model_evaluate(recs, holdout, data_description, topn=topn)\n",
    "\n",
    "        row = {}\n",
    "        if model_name is not None:\n",
    "            row[\"model\"] = model_name\n",
    "        else:\n",
    "            row[\"model\"] = \"noname\"\n",
    "\n",
    "        row[\"is_gower\"] = config[\"gower\"]\n",
    "        row[\"w_type\"] = config.get(\"w_type\", \"None\")\n",
    "        row.update(metrics._asdict())\n",
    "\n",
    "        res.append(row)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a9596f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"knn\": (build_iknn_model, iknn_model_scoring),\n",
    "    \"EASER\": (easer_build, easer_scoring),\n",
    "    \"fsSLIM\": (fsSLIM_build, fsSLIM_scoring),\n",
    "    \"HySVD\": (hysvd_build, hysvd_scoring),\n",
    "    \"EigenRec\": (eigenrec_build, eigenrec_scoring),\n",
    "}\n",
    "\n",
    "w_types = [\"builtin\", \"shap\", \"permutation\"]\n",
    "\n",
    "model_configs = {\n",
    "    \"knn\": [\n",
    "        {\"sampling\": False, \"gower\": True},\n",
    "        {\"sampling\": False, \"gower\": False},\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"sampling\": False,\n",
    "            \"gower\": True,\n",
    "            \"gower_w\": importances[w_type],\n",
    "            \"w_type\": w_type,\n",
    "        }\n",
    "        for w_type in w_types\n",
    "    ],\n",
    "    \"EASER\": [\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": True},\n",
    "        {\"alpha\": 1, \"l\": 100, \"gower\": False},\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"alpha\": 1,\n",
    "            \"l\": 100,\n",
    "            \"gower\": True,\n",
    "            \"gower_w\": importances[w_type],\n",
    "            \"w_type\": w_type,\n",
    "        }\n",
    "        for w_type in w_types\n",
    "    ],\n",
    "    \"fsSLIM\": [\n",
    "        {\"nnbrs\": 50, \"alpha_reg\": 1e-3, \"beta_reg\": 1e-1, \"gower\": True},\n",
    "        {\"nnbrs\": 50, \"alpha_reg\": 1e-3, \"beta_reg\": 1e-1, \"gower\": False},\n",
    "    ]\n",
    "    + [\n",
    "        {\n",
    "            \"nnbrs\": 50,\n",
    "            \"alpha_reg\": 1e-3,\n",
    "            \"beta_reg\": 1e-1,\n",
    "            \"gower\": True,\n",
    "            \"gower_w\": importances[w_type],\n",
    "            \"w_type\": w_type,\n",
    "        }\n",
    "        for w_type in w_types\n",
    "    ],\n",
    "    \"HySVD\": [\n",
    "        {\"gower\": True, \"rank\": 35},\n",
    "        {\"gower\": False, \"rank\": 35},\n",
    "    ]\n",
    "    + [\n",
    "        {\"gower\": True, \"rank\": 35, \"gower_w\": importances[w_type], \"w_type\": w_type}\n",
    "        for w_type in w_types\n",
    "    ],\n",
    "    \"EigenRec\": [{\"gower\": True, \"rank\": 50}, {\"gower\": False, \"rank\": 50}]\n",
    "    + [\n",
    "        {\"gower\": True, \"rank\": 50, \"gower_w\": importances[w_type], \"w_type\": w_type}\n",
    "        for w_type in w_types\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8263b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running knn: 100%|██████████| 5/5 [00:07<00:00,  1.57s/it]\n",
      "Running EASER: 100%|██████████| 5/5 [00:09<00:00,  1.91s/it]\n",
      "Running fsSLIM: 100%|██████████| 5/5 [00:47<00:00,  9.55s/it]\n",
      "Running HySVD: 100%|██████████| 5/5 [01:52<00:00, 22.56s/it]\n",
      "Running EigenRec: 100%|██████████| 5/5 [00:13<00:00,  2.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>is_gower</th>\n",
       "      <th>w_type</th>\n",
       "      <th>HR</th>\n",
       "      <th>MRR</th>\n",
       "      <th>Coverage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.001064</td>\n",
       "      <td>0.105968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.270496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>builtin</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.178472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>shap</td>\n",
       "      <td>0.007291</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.146960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.161461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EASER</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023526</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>builtin</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>shap</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>0.288901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EASER</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0.064498</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>0.288622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.065059</td>\n",
       "      <td>0.021077</td>\n",
       "      <td>0.258784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.060572</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>0.257111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>builtin</td>\n",
       "      <td>0.058890</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>0.251534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>shap</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>0.020449</td>\n",
       "      <td>0.258784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fsSLIM</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>0.021245</td>\n",
       "      <td>0.253765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.013385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>True</td>\n",
       "      <td>builtin</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.014222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>True</td>\n",
       "      <td>shap</td>\n",
       "      <td>0.019069</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.012828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HySVD</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>0.013943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>0.047672</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.098438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.045990</td>\n",
       "      <td>0.018376</td>\n",
       "      <td>0.085332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>builtin</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>0.014502</td>\n",
       "      <td>0.114334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>shap</td>\n",
       "      <td>0.043186</td>\n",
       "      <td>0.016214</td>\n",
       "      <td>0.115170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EigenRec</td>\n",
       "      <td>True</td>\n",
       "      <td>permutation</td>\n",
       "      <td>0.037577</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>0.112660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  is_gower       w_type        HR       MRR  Coverage\n",
       "0        knn      True         None  0.003926  0.001064  0.105968\n",
       "1        knn     False         None  0.006169  0.002085  0.270496\n",
       "2        knn      True      builtin  0.005609  0.001493  0.178472\n",
       "3        knn      True         shap  0.007291  0.001584  0.146960\n",
       "4        knn      True  permutation  0.004487  0.001287  0.161461\n",
       "5      EASER      True         None  0.064498  0.023526  0.288622\n",
       "6      EASER     False         None  0.064498  0.023526  0.288622\n",
       "7      EASER      True      builtin  0.064498  0.023621  0.288622\n",
       "8      EASER      True         shap  0.064498  0.023527  0.288901\n",
       "9      EASER      True  permutation  0.064498  0.023527  0.288622\n",
       "10    fsSLIM      True         None  0.065059  0.021077  0.258784\n",
       "11    fsSLIM     False         None  0.060572  0.021082  0.257111\n",
       "12    fsSLIM      True      builtin  0.058890  0.019749  0.251534\n",
       "13    fsSLIM      True         shap  0.060011  0.020449  0.258784\n",
       "14    fsSLIM      True  permutation  0.062255  0.021245  0.253765\n",
       "15     HySVD      True         None  0.023556  0.009088  0.013385\n",
       "16     HySVD     False         None  0.008413  0.002012  0.013385\n",
       "17     HySVD      True      builtin  0.015143  0.005775  0.014222\n",
       "18     HySVD      True         shap  0.019069  0.006933  0.012828\n",
       "19     HySVD      True  permutation  0.015143  0.005954  0.013943\n",
       "20  EigenRec      True         None  0.047672  0.017062  0.098438\n",
       "21  EigenRec     False         None  0.045990  0.018376  0.085332\n",
       "22  EigenRec      True      builtin  0.038699  0.014502  0.114334\n",
       "23  EigenRec      True         shap  0.043186  0.016214  0.115170\n",
       "24  EigenRec      True  permutation  0.037577  0.015324  0.112660"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for name, (build_fn, scoring_fn) in models.items():\n",
    "    result += compare_models(\n",
    "        configs=model_configs[name],\n",
    "        build_fn=build_fn,\n",
    "        scoring_fn=scoring_fn,\n",
    "        training=training,\n",
    "        testset=testset,\n",
    "        holdout=holdout,\n",
    "        data_description=data_description,\n",
    "        model_name=name,\n",
    "    )\n",
    "\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0bbcf97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationMetrics(HR=0.0005608524957936063, MRR=0.0005608524957936063, Coverage=0.9949804796430564)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluate(\n",
    "    topn_recommendations(random_scoring(testset, data_description), 10),\n",
    "    holdout,\n",
    "    data_description,\n",
    "    10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
